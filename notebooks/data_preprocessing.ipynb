{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will include code to clean, preprocess, and merge the datasets (e.g., handling missing values, merging data based on star/planet identifiers, normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 1: Load and assess the data '''\n",
    "# check out any columns that look useless, columns of interest, data type of columns (continous, categorical, timeseries, etc.)\n",
    "\n",
    "# turning the vot data to csv for GAIA\n",
    "from astropy.io.votable import parse\n",
    "\n",
    "votable = parse(\"../data/gaiaDR3HostStar.vot\") # Load the VOTable file\n",
    "\n",
    "table = votable.get_first_table().to_table() # Convert the first table in the VOTable to an Astropy Table\n",
    "\n",
    "table.write(\"../data/gaiaDR3HostStar.csv\", format=\"csv\", overwrite=True) # save to csv\n",
    "\n",
    "\n",
    "# Read the CSV files into a DataFrame\n",
    "dfGAIA = pd.read_csv('../data/gaiaDR3HostStar.csv')\n",
    "dfNASAExo = pd.read_csv('../data/NASA_Exoplanet_Archive.csv')\n",
    "dfDropPHL = pd.read_csv('../data/PHL_Exoplanet_Habitability.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 2: Clean and combine the data'''\n",
    "columnsDropGAIA = [] # for Gaia, merge with sourceID \n",
    "columnsDropNASAExo = [\"koi_disposition\", \"koi_pdisposition\", \"koi_score\", # not related to habitability\n",
    "                      \"koi_fpflag_nt\", \"koi_fpflag_ss\", \"koi_fpflag_co\", \"koi_fpflag_ec\", # not related to habitability\n",
    "                      \"koi_period_err1\", \"koi_period_err2\", \n",
    "                      \"koi_time0bk_err1\", \"koi_time0bk_err2\", \n",
    "                      \"koi_impact_err1\", \"koi_impact_err2\", \n",
    "                      \"koi_duration_err1\", \"koi_duration_err2\", \n",
    "                      \"koi_depth_err1\", \"koi_depth_err2\",\n",
    "                      \"koi_prad_err1\", \"koi_prad_err2\",\n",
    "                      \"koi_teq_err1\", \"koi_teq_err2\",\n",
    "                      \"koi_insol_err1\", \"koi_insol_err2\",\n",
    "                      \"koi_tce_plnt_num\", \"koi_tce_delivname\",\n",
    "                      \"koi_steff_err1\", \"koi_steff_err2\",\n",
    "                      \"koi_slogg_err1\", \"koi_slogg_err2\",\n",
    "                      \"koi_srad_err1\", \"koi_srad_err2\", # all columns above are plus/minus errors of their respective columns measurements, not important features\n",
    "                      ] # merge with kepler name, id and oi name? \n",
    "columnsDropPHL = [\"P_RADIUS\",\"P_RADIUS_ERROR_MIN\",\"P_RADIUS_ERROR_MAX\", \"P_MASS_ERROR_MIN\", \"P_MASS_ERROR_MAX\", # missing values in these columns\n",
    "                  \"P_YEAR\", \"P_UPDATED\", # not useful for habilitability\n",
    "                  \"P_PERIOD_ERROR_MIN\", \"P_PERIOD_ERROR_MAX\",\n",
    "                  \"P_SEMI_MAJOR_AXIS_ERROR_MIN\", \"P_SEMI_MAJOR_AXIS_ERROR_MAX\",\n",
    "                  \"P_ECCENTRICITY_ERROR_MIN\", \"P_ECCENTRICITY_ERROR_MAX\",\n",
    "                  \"P_INCLINATION_ERROR_MIN\", \"P_INCLINATION_ERROR_MAX\",\n",
    "                  \"P_OMEGA_ERROR_MIN\", \"P_OMEGA_ERROR_MAX\",\n",
    "                  \"P_TPERI_ERROR_MIN\", \"P_TPERI_ERROR_MAX\",\n",
    "                  \"P_IMPACT_PARAMETER\", \"P_IMPACT_PARAMETER_ERROR_MIN\", \n",
    "                  \"P_IMPACT_PARAMETER_ERROR_MAX\", \"P_TEMP_MEASURED\", \"P_GEO_ALBEDO\", \n",
    "                  \"P_GEO_ALBEDO_ERROR_MIN\", \"P_GEO_ALBEDO_ERROR_MAX\", \"P_DETECTION\",\n",
    "                  \"P_DETECTION_MASS\", \"P_DETECTION_RADIUS\", \"P_ALT_NAMES\", \"P_ATMOSPHERE\",\n",
    "                  \"S_DISTANCE_ERROR_MIN\", \"S_DISTANCE_ERROR_MAX\",\n",
    "                  \"S_METALLICITY_ERROR_MIN\", \"S_METALLICITY_ERROR_MAX\",\n",
    "                  \"S_MASS_ERROR_MIN\", \"S_MASS_ERROR_MAX\", \n",
    "                  \"S_RADIUS_ERROR_MIN\", \"S_RADIUS_ERROR_MAX\",\n",
    "                  \"S_AGE_ERROR_MIN\", \"S_AGE_ERROR_MAX\",\n",
    "                  \"S_TEMPERATURE_ERROR_MIN\", \"S_TEMPERATURE_ERROR_MAX\", \n",
    "                  \"S_DISC\", \"S_MAGNETIC_FIELD\", \n",
    "                  \"S_ALT_NAMES\", \"P_ESCAPE\", \"P_POTENTIAL\", \"P_GRAVITY\", \"P_DENSITY\",\n",
    "                  \"S_TYPE_TEMP\", \"P_TYPE_TEMP\",\n",
    "                  \"S_CONSTELLATION\", \"S_CONSTELLATION_ABR\", \"S_CONSTELLATION_ENG\",\n",
    "                  \"S_RA_H\", \"S_RA_T\", \"S_DEC_T\" # all columns above are plus/minus errors of their respective columns measurements or not important features that helps with habilitability \n",
    "                   ] # merge with p name (planet name) or s name (star name)?\n",
    "\n",
    "\n",
    "# dropping columns and recreating csv's\n",
    "dfGAIA = dfGAIA.drop(columns=columnsDropGAIA)\n",
    "dfNASAExo = dfNASAExo.drop(columns=columnsDropNASAExo)\n",
    "dfDropPHL = dfDropPHL.drop(columns=columnsDropPHL)\n",
    "\n",
    "\n",
    "dfGAIA.to_csv('../data/droppeddata/GAIA.csv', index=False)\n",
    "dfNASAExo.to_csv('../data/droppeddata/NASAExo.csv', index=False)\n",
    "dfDropPHL.to_csv('../data/droppeddata/PHL.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
