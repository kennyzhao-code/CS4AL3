{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will include code to clean, preprocess, and merge the datasets (e.g., handling missing values, merging data based on star/planet identifiers, normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 1: Load and assess the data '''\n",
    "# check out any columns that look useless, columns of interest, data type of columns (continous, categorical, timeseries, etc.)\n",
    "\n",
    "# turning the vot data to csv for GAIA\n",
    "from astropy.io.votable import parse\n",
    "\n",
    "votable = parse(\"../data/gaiaDR3HostStar.vot\") # Load the VOTable file\n",
    "\n",
    "table = votable.get_first_table().to_table() # Convert the first table in the VOTable to an Astropy Table\n",
    "\n",
    "table.write(\"../data/gaiaDR3HostStar.csv\", format=\"csv\", overwrite=True) # save to csv\n",
    "\n",
    "# Read the CSV files into a DataFrame\n",
    "dfGAIA = pd.read_csv('../data/gaiaDR3HostStar.csv')\n",
    "dfNASAExo = pd.read_csv('../data/NASA_Exoplanet_Archive.csv')\n",
    "dfDropPHL = pd.read_csv('../data/PHL_Exoplanet_Habitability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Step 2: Clean and combine the data'''\n",
    "columnsDropGAIA = [] # for Gaia, merge with sourceID \n",
    "columnsDropNASAExo = [\"koi_disposition\", \"koi_pdisposition\", \"koi_score\", # not related to habitability\n",
    "                      \"koi_fpflag_nt\", \"koi_fpflag_ss\", \"koi_fpflag_co\", \"koi_fpflag_ec\", # not related to habitability\n",
    "                      \"koi_period_err1\", \"koi_period_err2\", \n",
    "                      \"koi_time0bk_err1\", \"koi_time0bk_err2\", \n",
    "                      \"koi_impact_err1\", \"koi_impact_err2\", \n",
    "                      \"koi_duration_err1\", \"koi_duration_err2\", \n",
    "                      \"koi_depth_err1\", \"koi_depth_err2\",\n",
    "                      \"koi_prad_err1\", \"koi_prad_err2\",\n",
    "                      \"koi_teq_err1\", \"koi_teq_err2\",\n",
    "                      \"koi_insol_err1\", \"koi_insol_err2\",\n",
    "                      \"koi_tce_plnt_num\", \"koi_tce_delivname\",\n",
    "                      \"koi_steff_err1\", \"koi_steff_err2\",\n",
    "                      \"koi_slogg_err1\", \"koi_slogg_err2\",\n",
    "                      \"koi_srad_err1\", \"koi_srad_err2\", # all columns above are plus/minus errors of their respective columns measurements, not important features\n",
    "                      ] # merge with kepler name, id and oi name? \n",
    "columnsDropPHL = [\"P_RADIUS\",\"P_RADIUS_ERROR_MIN\",\"P_RADIUS_ERROR_MAX\", \"P_MASS_ERROR_MIN\", \"P_MASS_ERROR_MAX\", # missing values in these columns\n",
    "                  \"P_YEAR\", \"P_UPDATED\", # not useful for habilitability\n",
    "                  \"P_PERIOD_ERROR_MIN\", \"P_PERIOD_ERROR_MAX\",\n",
    "                  \"P_SEMI_MAJOR_AXIS_ERROR_MIN\", \"P_SEMI_MAJOR_AXIS_ERROR_MAX\",\n",
    "                  \"P_ECCENTRICITY_ERROR_MIN\", \"P_ECCENTRICITY_ERROR_MAX\",\n",
    "                  \"P_INCLINATION_ERROR_MIN\", \"P_INCLINATION_ERROR_MAX\",\n",
    "                  \"P_OMEGA_ERROR_MIN\", \"P_OMEGA_ERROR_MAX\",\n",
    "                  \"P_TPERI_ERROR_MIN\", \"P_TPERI_ERROR_MAX\",\n",
    "                  \"P_IMPACT_PARAMETER\", \"P_IMPACT_PARAMETER_ERROR_MIN\", \n",
    "                  \"P_IMPACT_PARAMETER_ERROR_MAX\", \"P_TEMP_MEASURED\", \"P_GEO_ALBEDO\", \n",
    "                  \"P_GEO_ALBEDO_ERROR_MIN\", \"P_GEO_ALBEDO_ERROR_MAX\", \"P_DETECTION\",\n",
    "                  \"P_DETECTION_MASS\", \"P_DETECTION_RADIUS\", \"P_ALT_NAMES\", \"P_ATMOSPHERE\",\n",
    "                  \"S_DISTANCE_ERROR_MIN\", \"S_DISTANCE_ERROR_MAX\",\n",
    "                  \"S_METALLICITY_ERROR_MIN\", \"S_METALLICITY_ERROR_MAX\",\n",
    "                  \"S_MASS_ERROR_MIN\", \"S_MASS_ERROR_MAX\", \n",
    "                  \"S_RADIUS_ERROR_MIN\", \"S_RADIUS_ERROR_MAX\",\n",
    "                  \"S_AGE_ERROR_MIN\", \"S_AGE_ERROR_MAX\",\n",
    "                  \"S_TEMPERATURE_ERROR_MIN\", \"S_TEMPERATURE_ERROR_MAX\", \n",
    "                  \"S_DISC\", \"S_MAGNETIC_FIELD\", \n",
    "                  \"S_ALT_NAMES\", \"P_ESCAPE\", \"P_POTENTIAL\", \"P_GRAVITY\", \"P_DENSITY\",\n",
    "                  \"S_TYPE_TEMP\", \"P_TYPE_TEMP\",\n",
    "                  \"S_CONSTELLATION\", \"S_CONSTELLATION_ABR\", \"S_CONSTELLATION_ENG\",\n",
    "                  \"S_RA_H\", \"S_RA_T\", \"S_DEC_T\" # all columns above are plus/minus errors of their respective columns measurements or not important features that helps with habilitability \n",
    "                   ] # merge with p name (planet name) or s name (star name)?\n",
    "\n",
    "\n",
    "# dropping columns and recreating csv's\n",
    "dfGAIA = dfGAIA.drop(columns=columnsDropGAIA)\n",
    "dfNASAExo = dfNASAExo.drop(columns=columnsDropNASAExo)\n",
    "dfDropPHL = dfDropPHL.drop(columns=columnsDropPHL)\n",
    "\n",
    "\n",
    "dfGAIA.to_csv('../data/droppeddata/GAIA.csv', index=False)\n",
    "dfNASAExo.to_csv('../data/droppeddata/NASAExo.csv', index=False)\n",
    "dfDropPHL.to_csv('../data/droppeddata/PHL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 3: Merge NASAExo and PHL'''\n",
    "\n",
    "# Load preprocessed datasets\n",
    "dfNASAExo = pd.read_csv('../data/droppeddata/NASAExo.csv')\n",
    "dfPHL = pd.read_csv('../data/droppeddata/PHL.csv')\n",
    "\n",
    "# Rename columns for consistency\n",
    "dfPHL.rename(columns={\"P_NAME\": \"planet_name\", \"S_NAME\": \"star_name\"}, inplace=True)\n",
    "dfNASAExo.rename(columns={\"kepler_name\": \"planet_name\"}, inplace=True)\n",
    "\n",
    "# Perform merges\n",
    "finalMerge = pd.merge(dfNASAExo, dfPHL, on=\"planet_name\", how=\"left\")\n",
    "finalMerge.to_csv('../data/mergeddata/merged_NASAExo_PHL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASAExo_PHL (ICRS) RA Range: 279.85272 to 301.72076\n",
      "NASAExo_PHL (ICRS) DEC Range: 36.577381 to 52.33601\n",
      "GAIA RA Range: 156.3226 to 316.6688\n",
      "GAIA DEC Range: -64.3699 to 76.031\n"
     ]
    }
   ],
   "source": [
    "'''Step 4: Merge GAIA and NASAExo_PHL'''\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "NASAExo_PHL = pd.read_csv('../data/mergeddata/merged_NASAExo_PHL.csv')\n",
    "GAIA = pd.read_csv('../data/droppeddata/GAIA.csv')\n",
    "\n",
    "GAIA['ra'] = GAIA['ra'].round(4)\n",
    "GAIA['dec'] = GAIA['dec'].round(4)\n",
    "\n",
    "# Creating SkyCoord objects for matching\n",
    "NASAExo_PHL_coords = SkyCoord(ra=NASAExo_PHL['ra'].values * u.degree, \n",
    "                              dec=NASAExo_PHL['dec'].values * u.degree, \n",
    "                              frame='icrs')\n",
    "GAIA_coords = SkyCoord(ra=GAIA['ra'].values * u.degree, \n",
    "                       dec=GAIA['dec'].values * u.degree, \n",
    "                       frame='icrs')\n",
    "\n",
    "# Transform NASAExo_PHL to ICRS\n",
    "NASAExo_PHL_coords_icrs = NASAExo_PHL_coords.transform_to('icrs')\n",
    "\n",
    "# Debug range of coordinates\n",
    "print(\"NASAExo_PHL (ICRS) RA Range:\", NASAExo_PHL_coords_icrs.ra.deg.min(), \"to\", NASAExo_PHL_coords_icrs.ra.deg.max())\n",
    "print(\"NASAExo_PHL (ICRS) DEC Range:\", NASAExo_PHL_coords_icrs.dec.deg.min(), \"to\", NASAExo_PHL_coords_icrs.dec.deg.max())\n",
    "print(\"GAIA RA Range:\", GAIA['ra'].min(), \"to\", GAIA['ra'].max())\n",
    "print(\"GAIA DEC Range:\", GAIA['dec'].min(), \"to\", GAIA['dec'].max())\n",
    "\n",
    "# Perform SkyCoord Matching\n",
    "idx, d2d, _ = GAIA_coords.match_to_catalog_sky(NASAExo_PHL_coords_icrs)\n",
    "matches = d2d < 1 * u.arcsecond\n",
    "\n",
    "# Filter matched pairs\n",
    "GAIA_matches = GAIA[matches]\n",
    "NASAExo_PHL_matches = NASAExo_PHL.iloc[idx[matches]]\n",
    "\n",
    "# Merge matched datasets\n",
    "mergedDF = pd.concat([NASAExo_PHL_matches.reset_index(drop=True), GAIA_matches.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Export final merged dataset to CSV\n",
    "mergedDF.to_csv('../data/mergeddata/GAIA_NASAExo_PHL_merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
